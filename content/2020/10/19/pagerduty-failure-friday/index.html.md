---
title: PagerDutyのFailure Fridayという文化
date: 2020-10-19T21:00:00+09:00
---

PagerDuty Incident Responseの邦訳をした時に、PagerDuty内のFailure Fridayというイベントが紹介されていました。
さっと流し読みした感じFailure Injection的な何かかな？って理解だったのですが、改めてよく読んでみたのでそれの解説をしようと思います。



PagerDutonianに私たちのサービスの最も重要な要件は何であるかを尋ねると、同じ答えが得られます:信頼性。
お客様は、システムに問題が発生したときにアラートを出すことを私たちに頼っています。時間通りに、毎回、昼夜を問わず。


PagerDutyは、2013年の時点で、3つのデータセンターと2つのクラウドプロバイダーにデプロイされ、
すべての電話、SMS、プッシュ通知、および電子メールアラートが確実に配信されるようにします。
クリティカルパスにはバックアップがあります。
そして、バックアップ用のバックアップがあります。
この三重の冗長性により、アラートで眠ったり、テキストメッセージを見逃したり、電子メールを受信したりすることはありません。

## 耐障害性設計以上のものが必要


耐障害性のある設計を持つことは素晴らしいことですが、これらの設計が意図したとおりに
動作しない原因となる実装上の問題がある場合があります。
たとえば、問題が発生したときにのみ開始されるバックアップは、
テスト環境ではうまく機能するが、本番環境の負荷にさらされると失敗するバグやコードを隠すことができます。
クラウドホスティングでは、インフラストラクチャの障害をいつでも計画する必要があります。

インターネット自体でさえ失敗の原因です。データセンター間の遅延とパケット損失が定期的に劇的に増加しています。これらのイベントの一部は、DDoS攻撃などの既知の問題にまでさかのぼることができますが、原因の一部は不明です。どちらの場合も、これらのイベントについては、周囲のエンジニア以外にできることは何もありません。

### ミリ秒単位のクロスデータセンターレイテンシ


Netflixは、アプリケーションの障害回復力をテストする一連の自動化ツールであるSimianArmyを使用してこれらの問題を解決しました。
- Chaos Monkeyは、自動スケーリンググループを介して再生成されるインスタンスをシャットダウンします。
- Latency Monkeyは、ネットワーク呼び出しに人為的なレイテンシーを導入します。
- Chaos Gorillaは、アベイラビリティーゾーン全体をシャットダウンします。
これらのツールの一部は無料で利用できますが、アプリケーションがauto-scaling groupsを使用してAWSにのみデプロイされ、
当社のツールが複数のプロバイダーにデプロイされていることを前提としています。

独自の同等のツールを作成しようとして行き詰まりたくないので、私たちは簡単な方法に投資することにしました。
単に、会議をスケジュールして手動で行います。すべてのテストに共通のLinuxコマンドを使用しているため、簡単に開始できます。

## PagerDuty Failure Friday Benefits

ここ数ヶ月、PagerDutyでFailureFridayを実行しています。すでに多くの利益があります。



- Uncovers implementation issues that reduce our resiliency.
- Proactively discovers deficiencies to avoid these discrepancies becoming the root cause of a future outage.
- Builds a strong team culture by coming together as a team once a week to share knowledge. Ops can learn how the development teams debug production issues in their systems. Devs gain a better understanding of how their software is deployed. And it’s a nice perk to train new hires on how to handle outages at 11am on Friday than 3 AM on a Saturday.
- Reminds us that failure will happen. Failure is no longer considered a freak occurrence that can be ignored or explained away. All code that the engineering teams write is now tested against how it will survive during Failure Friday.

## 金曜日の失敗に備えてチームを準備する



Failure Fridayが始まる前に、私たちが紹介したいすべてのFailureの議題を作成することが重要です。
1時間の会議をスケジュールし、できるだけ多くの問題に取り組みます。

障害を注入すると、私たちが望むよりも深刻な障害が発生する可能性があるため、
チームの全員がシステムに障害を導入するという考えに賛同することが重要です。
リスクを軽減するために、チームの全員に通知が届き、参加していることを確認します。

最初の攻撃の準備として、その時間に実行するようにスケジュールされているすべてのcronジョブを無効にします。
私たちが攻撃しようとしているサービスのチームは、障害が注入されているときにシステムを監視するための
ダッシュボードを用意します。

Failure Friday実行中はコミュニケーションは不可欠です。
PagerDutyでは、専用のHipChatルームと電話会議を使用して、情報をすばやく交換できるようにします。
チャットルームがあると、実行されたアクションのタイムスタンプ付きログが得られ、
キャプチャしたメトリックと相関させることができるため、特に便利です。

また、PagerDutyアラートをオンにしたままにして、アラートを受信していることを確認し、
発生した障害に関連してアラートがどれだけ早く到着するかを確認します。

## Introducing Failure to Our System

各攻撃は5分間続きます。
その間には、常にサービスを完全に機能する状態に戻し、すべてが正しく動作していることを確認してから、次の攻撃に進みます。

攻撃中、ダッシュボードをチェックして、問題を示しているメトリックと、
その問題が他のシステムにどのように影響するかを理解します。
また、チャットルームには、いつページが表示されたか、そのページがどれほど役に立ったかをメモしておきます。

攻撃ごとに、最初に1つのホストを攻撃することから始めます。
その攻撃が期待どおりに動作する場合は、データセンター全体に対してテストを繰り返します。
AWSでのみホストされているサービスの場合、サービスがアベイラビリティーゾーン全体を失っても存続することをテストします。

### Attack #1: Process Failure

最初の攻撃は非常に単純で、サービスを5分間停止します。

この容量を失っても、サービス全体がトラフィックの処理を継続することを期待しています。
また、アラームがこのサービスを利用できないものとして正しく識別しているかどうかもよくわかります。
再開するには

```
sudo service cassandra stop
```

### Attack #2: Reboot Hosts

単一のノードとデータセンター全体の損失を乗り切ることができることを確認した後、マシンの再起動に移ります。
この攻撃は、再起動時に、マシンが必要なすべてのサービスを正しく開始することを確認します。
監視システムがサービスを実行しているマシンに関連付けられているインスタンスを見つけるのにも役立つため、
シャットダウン中にアラートが表示されることはありません。

### Attack #3: Network Isolation

前の2つの攻撃では、サービスが正常にシャットダウンされ、ボックスが再起動されました。
次の攻撃では、予期しない障害に対する回復力を確認します。
`iptables`を介したネットワーク接続をブロックします。
インバウンドパケットとアウトバウンドパケットの両方をドロップします。
このテストでは、クライアントに適切なタイムアウトが構成されており、
クリーンなサービスのシャットダウンに依存していないことを確認します。

### Attack #4: Network Slowness

最後の攻撃では、サービスがどのように速度低下を処理するかをテストします。
`tc`を使用して、ネットワークレベルで低速サービスをシミュレートします。

  sudo tc qdisc add dev eth0 root netem delay 500ms 100ms loss 5％

このコマンドは、すべてのネットワークトラフィックに400〜600ミリ秒の遅延を追加します。
また、適切な測定のために5％のパケット損失があります。
この障害により、通常、パフォーマンスの低下が予想されます。
理想的には、クライアントは遅延を回避できます。
たとえば、Cassandraクライアントは、より高速なノードと通信し、障害のあるノードにトラフィックを送信しないようにすることを選択する場合があります。
この攻撃は、ダッシュボードが低速ノードをどの程度適切に識別しているかをテストします。これは、ライブSSHセッションにも影響することに注意してください。

## まとめ

金曜日の失敗が終わったら、すべて明確なメッセージを投稿し、cronジョブを再度有効にします。
最後のステップは、実用的な学習を行い、それらをJIRAのチームメンバーの1人に割り当てることです。

Failure Fridayは、問題の修正を超えて、問題の発生を防ぐのに役立ちます。
PagerDutyの信頼性は私たちにとって非常に重要であり、FailureFridayにチームを参加させることが私たちの維持方法です。

詳細を知りたいですか？ダグ・バースが、ここPagerDuty HQで撮影されたFailureFridayについて講演しています。



